{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05aa8b55",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the rome_rents_clean.csv dataset into a pandas dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('italy-house-prices/rome_rents_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5de61c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove datetime column \n",
    "df = df.drop(columns=['datetime'])\n",
    "df = df.replace(['invalid', 'None', 'nan', ','], np.nan)\n",
    "df = df.dropna(how='any')  # Drop rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide \"stato\" column into two columns: \"condizioni\" and \"ristrutturato\"\n",
    "df[['condizioni', 'ristrutturato']] = df['stato'].str.split(' / ', expand=True)\n",
    "df = df.drop(columns=['stato'])\n",
    "print(df['condizioni'].unique())\n",
    "# transform into numerical values the \"stato\" column\n",
    "traslations_dict = {\n",
    "    'da ristrutturare': 0,\n",
    "    'buono': 1,\n",
    "    'ottimo': 2,\n",
    "    'nuovo': 3\n",
    "}\n",
    "# remove the \"ristrutturato\" column, instead create a int column \"in costruzione\" which is 1 if \"ristrutturato\" is \"in costruzione\", 0 otherwise\n",
    "df['in costruzione'] = (df['ristrutturato'] == 'in costruzione')\n",
    "df = df.drop(columns=['ristrutturato'])\n",
    "df['condizioni'] = df['condizioni'].map(traslations_dict)\n",
    "# translate the classe energetica column into numerical values\n",
    "# first print all different values in the \"classe energetica\" column\n",
    "print(\"Different values in 'classe energetica' column:\")\n",
    "print(df['classe energetica'].unique())\n",
    "# then create a dictionary to map the values\n",
    "classe_energetica_dict = {\n",
    "    'A+': 7,\n",
    "    'A': 6,\n",
    "    'B': 5,\n",
    "    'C': 4,\n",
    "    'D': 3,\n",
    "    'E': 2,\n",
    "    'F': 1,\n",
    "    'G': 0\n",
    "}\n",
    "df['classe energetica'] = df['classe energetica'].map(classe_energetica_dict)\n",
    "df['posti auto'] = df['posti auto'].astype('int8')\n",
    "df['bagni'] = df['bagni'].astype('int8')\n",
    "df['stanze'] = df['stanze'].astype('int8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where it is the only one with that value in \"quartiere\" column\n",
    "quartiere_counts = df['quartiere'].value_counts()\n",
    "rare_quartieri = quartiere_counts[quartiere_counts == 1].index\n",
    "df = df[~df['quartiere'].isin(rare_quartieri)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the file quartieri_mapping.csv which contains more info about each quartiere\n",
    "quartieri_df = pd.read_csv('italy-house-prices/quartieri_mapping.csv')\n",
    "# merge the two dataframes on the \"quartiere\" column\n",
    "df = df.merge(quartieri_df, left_on='quartiere', right_on='Quartiere', how='left')\n",
    "# drop the \"Quartiere\" column\n",
    "df = df.drop(columns=['Quartiere'])\n",
    "# represent \"Zone\" column as categorical values using one-hot encoding\n",
    "zone_dummies = pd.get_dummies(df['Zone'], prefix='Zone')\n",
    "df = pd.concat([df, zone_dummies], axis=1)\n",
    "df = df.drop(columns=['Zone'])\n",
    "# represent \"Zone_\" columns as int\n",
    "for col in zone_dummies.columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "# remove rows where any value is NaN\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# one-hot encode the \"quartiere\" column\n",
    "quartiere_dummies = pd.get_dummies(df['quartiere'], prefix='quartiere')\n",
    "df = pd.concat([df, quartiere_dummies], axis=1)\n",
    "df = df.drop(columns=['quartiere'])\n",
    "# represent \"quartiere_\" columns as int\n",
    "for col in quartiere_dummies.columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73354537",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb695b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add feature \"superficie**2\"\n",
    "df['superficie_squared'] = df['superficie'] ** 2\n",
    "# add feature \"mq_per_stanza\"\n",
    "df['mq_per_stanza'] = df['superficie'] / df['stanze']\n",
    "# add feature \"stanze totali\"\n",
    "df['stanze_totali'] = df['stanze'] + df['bagni']\n",
    "# add feature \"prezzo_per_mq\"\n",
    "df['prezzo_al_mq'] = df['prezzo'] / df['superficie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the target variable for classification: y_classificazione\n",
    "# if prezzo_al_mq is greater than mean_prezzo_al_mq, then y_classificazione is 1, otherwise 0\n",
    "\n",
    "mean_prezzo_al_mq = df['prezzo_al_mq'].mean()\n",
    "df['y_classificazione'] = (df['prezzo_al_mq'] > mean_prezzo_al_mq).astype(int)\n",
    "# print also prezzo al mq mean of Rome rents\n",
    "print(f\"Mean prezzo al mq of Rome rents: {mean_prezzo_al_mq}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b2897",
   "metadata": {},
   "source": [
    "### Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers based on 'superficie' and 'prezzo' columns using the IQR method\n",
    "Q1 = df[['superficie', 'prezzo']].quantile(0.20)\n",
    "Q3 = df[['superficie', 'prezzo']].quantile(0.80)\n",
    "IQR = Q3 - Q1\n",
    "filter = ~((df[['superficie', 'prezzo']] < (Q1 - 1.5 * IQR)) | (df[['superficie', 'prezzo']] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "cleaned_data = df.loc[filter].reset_index(drop=True)\n",
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b22fed",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the numerical features using StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "# split into training, validation, and test set\n",
    "from random import randint\n",
    "# get random number to use as random_state\n",
    "random_state = randint(0, 10000)\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.1, random_state=random_state)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=random_state)\n",
    "# separate features and target variable for regression and classification\n",
    "X_train = train_df.drop(columns=['prezzo', 'y_classificazione'])\n",
    "y_train_regression = train_df['prezzo']\n",
    "y_train_classification = train_df['y_classificazione']\n",
    "X_val = val_df.drop(columns=['prezzo', 'y_classificazione'])\n",
    "y_val_regression = val_df['prezzo']\n",
    "y_val_classification = val_df['y_classificazione']\n",
    "X_test = test_df.drop(columns=['prezzo', 'y_classificazione'])\n",
    "y_test_regression = test_df['prezzo']\n",
    "y_test_classification = test_df['y_classificazione']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize only numerical columns using StandardScaler\n",
    "numerical_cols = ['superficie', 'superficie_squared', 'posti auto', 'stanze', 'mq_per_stanza', 'stanze_totali', 'prezzo_al_mq']\n",
    "print(\"Numerical columns to be normalized:\")\n",
    "print(numerical_cols)\n",
    "scaler = RobustScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9fa3fd",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear regression model to predict the price\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "y_train_log = np.log(y_train_regression)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv_scores = cross_val_score(reg_model, X_train, y_train_log, cv=5, scoring='neg_mean_squared_error')\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation MSE scores:\", -cv_scores)\n",
    "print(\"Mean cross-validation MSE:\", -cv_scores.mean())\n",
    "\n",
    "# Fit the model on the entire training set\n",
    "reg_model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "y_pred_log = reg_model.predict(X_test)\n",
    "# Convert predictions back to the original scale\n",
    "y_pred_original = np.exp(y_pred_log)\n",
    "\n",
    "# calculate mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# print overall mse\n",
    "mse = mean_squared_error(y_test_regression, y_pred_original)\n",
    "print(f\"Mean Squared Error on test set: {mse:.2f}\")\n",
    "\n",
    "# calculate abs error based on zone (Zone_Center, Zone_North, Zone_Northeast, Zone_East, Zone_Southeast, Zone_South, Zone_Southwest, Zone_West, Zone_Northwest)\n",
    "zones = [col for col in X_test.columns if col.startswith('Zone_')]\n",
    "for zone in zones:\n",
    "    zone_mask = (X_test[zone] == 1)\n",
    "    # if no samples in this zone, skip\n",
    "    if zone_mask.sum() == 0:\n",
    "        continue\n",
    "    zone_abs_errors = np.abs(y_test_regression[zone_mask] - y_pred_original[zone_mask])\n",
    "    zone_mse = mean_squared_error(y_test_regression[zone_mask], y_pred_original[zone_mask])\n",
    "    print(f\"Zone: {zone}, absolute error mean: {zone_abs_errors.mean():.2f}, MSE: {zone_mse:.2f}\")\n",
    "\n",
    "# print some predictions vs actual values divided by zone\n",
    "for zone in zones:\n",
    "    zone_mask = (X_test[zone] == 1)\n",
    "    # if no samples in this zone, skip\n",
    "    if zone_mask.sum() == 0:\n",
    "        continue\n",
    "    print(f\"Predictions for zone {zone}:\")\n",
    "    for i in range(min(5, zone_mask.sum())):\n",
    "        idx = np.where(zone_mask)[0][i]\n",
    "        print(f\"Predicted: {y_pred_original[idx]:.2f}, Actual: {y_test_regression.iloc[idx]:.2f}\")\n",
    "\n",
    "# Predicted vs Actual plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_regression, y_pred_original, alpha=0.7, color='blue')\n",
    "plt.plot([y_test_regression.min(), y_test_regression.max()], [y_test_regression.min(), y_test_regression.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Predicted vs Actual Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caafb5a3",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation\n",
    "\n",
    "In this section, we will evaluate the models using the following metrics:\n",
    "\n",
    "- Accuracy, Precision, Recall, and F1 Score\n",
    "- Confusion Matrix\n",
    "- ROC and AUC (binary and multiclass)\n",
    "- Training vs. Validation Performance\n",
    "- Optional: Computational cost and training time\n",
    "\n",
    "We will also visualize these metrics using appropriate graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1031d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Evaluate regression model\n",
    "start_time = time.time()\n",
    "y_pred_regression = reg_model.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test_regression, y_pred_regression)\n",
    "r2 = r2_score(y_test_regression, y_pred_regression)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "print(f\"Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Residuals plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "residuals = y_test_regression - y_pred_regression\n",
    "sns.histplot(residuals, kde=True, bins=30, color='blue')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# predicted vs actual (fit to the data)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_regression, y_pred_regression, alpha=0.7, color='green')\n",
    "plt.plot([y_test_regression.min(), y_test_regression.max()], [y_test_regression.min(), y_test_regression.max()], 'k--', lw=2)\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# plot feature importance (first 20 features) based on absolute value of coefficients\n",
    "feature_importance = np.abs(reg_model.coef_)\n",
    "features = X_train.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average error based on zona \n",
    "zones = [col for col in X_test.columns if col.startswith('Zone_')]\n",
    "zone_errors_data = []\n",
    "for zone in zones:\n",
    "    zone_mask = (X_test[zone] == 1)\n",
    "    # if no samples in this zone, skip\n",
    "    if zone_mask.sum() == 0:\n",
    "        continue\n",
    "    zone_errors = np.abs(y_test_regression[zone_mask] - y_pred_original[zone_mask])\n",
    "    avg_error_euro = zone_errors.mean()\n",
    "    zone_errors_data.append({'Zone': zone.replace('Zone_', ''), 'Avg Error (€)': avg_error_euro, 'Samples': zone_mask.sum()})\n",
    "\n",
    "# Create DataFrame\n",
    "zone_errors_df = pd.DataFrame(zone_errors_data)\n",
    "\n",
    "# Print table\n",
    "print(\"Average Error in Euro by Zone:\")\n",
    "print(\"-\" * 50)\n",
    "print(zone_errors_df.to_string(index=False))\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(zone_errors_df['Zone'], zone_errors_df['Avg Error (€)'], color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Zone', fontsize=12)\n",
    "plt.ylabel('Average Error (€)', fontsize=12)\n",
    "plt.title('Average Prediction Error by Zone', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'€{height:.0f}',\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe8e6a",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7364e",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "nb_model = GaussianNB()\n",
    "# Perform cross-validation on the training set\n",
    "cv_scores_nb = cross_val_score(nb_model, X_train, y_train_classification, cv=5, scoring='accuracy')\n",
    "# Print cross-validation results\n",
    "print(\"Naive Bayes Cross-validation accuracy scores:\", cv_scores_nb)\n",
    "print(\"Mean cross-validation accuracy:\", cv_scores_nb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4007e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit and predict with Naive Bayes Classifier\n",
    "nb_model.fit(X_train, y_train_classification)\n",
    "y_pred_classification = nb_model.predict(X_test)\n",
    "# Evaluate classification model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_test_classification, y_pred_classification)\n",
    "precision = precision_score(y_test_classification, y_pred_classification)\n",
    "recall = recall_score(y_test_classification, y_pred_classification)\n",
    "f1 = f1_score(y_test_classification, y_pred_classification)\n",
    "conf_matrix = confusion_matrix(y_test_classification, y_pred_classification)\n",
    "print(\"Naive Bayes Classification Accuracy:\", accuracy)\n",
    "print(\"Naive Bayes Classification Precision:\", precision)\n",
    "print(\"Naive Bayes Classification Recall:\", recall)\n",
    "print(\"Naive Bayes Classification F1 Score:\", f1)\n",
    "print(\"Naive Bayes Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735fd02",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "# Perform cross-validation on the training set\n",
    "cv_scores_logreg = cross_val_score(logreg_model, X_train, y_train_classification, cv=5, scoring='accuracy')\n",
    "# Print cross-validation results\n",
    "print(\"Logistic Regression Cross-validation accuracy scores:\", cv_scores_logreg)\n",
    "print(\"Mean cross-validation accuracy:\", cv_scores_logreg.mean())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871447e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit and prefict with Logistic Regression Classifier\n",
    "logreg_model.fit(X_train, y_train_classification)\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "# Evaluate classification model\n",
    "accuracy_logreg = accuracy_score(y_test_classification, y_pred_logreg)\n",
    "precision_logreg = precision_score(y_test_classification, y_pred_logreg)\n",
    "recall_logreg = recall_score(y_test_classification, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test_classification, y_pred_logreg)\n",
    "conf_matrix_logreg = confusion_matrix(y_test_classification, y_pred_logreg)\n",
    "print(\"Logistic Regression Classification Accuracy:\", accuracy_logreg)\n",
    "print(\"Logistic Regression Classification Precision:\", precision_logreg)\n",
    "print(\"Logistic Regression Classification Recall:\", recall_logreg)\n",
    "print(\"Logistic Regression Classification F1 Score:\", f1_logreg)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", conf_matrix_logreg)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
